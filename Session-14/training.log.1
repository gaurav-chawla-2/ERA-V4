python train.py
Using device: cuda
Precision: bfloat16
Model Parameters: 288.38M
Compiling model...
Model compiled.

Starting Training for 10000 steps (from 0)...
Training:  10%|█████████████▊                                                                                                                            | 999/10000 [19:31<2:53:49,  1.16s/it, loss=2.2, lr=0.000598]
[Step 1000] Avg Loss: 2.6675
Generation: Once upon a time to alsorib the
 that bear bear.
Your will dry-morrow have you conceive aPrin,
That away false; like the begun to cipher
Would long ere this sometimes youno more;
But I spent spent, yet
Training:  20%|██████████████████████████▉                                                                                                            | 1999/10000 [39:02<2:34:58,  1.16s/it, loss=0.202, lr=0.000582]
[Step 2000] Avg Loss: 0.2687
Generation: Once upon a time to
Had all the life and have let me speak.

JOHN OF GAUNT:
O, the stroke of faith
Thy succeeders last pronounce that mouse,
I play'd thee.

HENRY B
Training:  30%|████████████████████████████████████████▍                                                                                              | 2999/10000 [58:01<2:13:40,  1.15s/it, loss=0.189, lr=0.000552]
[Step 3000] Avg Loss: 0.1574
Generation: Once upon a time!

GREMIO:
My pretty sought, you ne'er a bare- Euro;
Titusitus thought to part thatCome,irmirmirm:
How if you me to have me?

 out of me,
Training:  40%|█████████████████████████████████████████████████████▌                                                                                | 3999/10000 [1:17:18<1:53:36,  1.14s/it, loss=0.111, lr=0.00051]
[Step 4000] Avg Loss: 0.1066
Generation: Once upon a time,
Unless that the Conversion side wereinging to the let him
And several several several powers.

QUEEN ELIZABETH:
The loss of such easy groans!

KING RICHARD III:
The heavens
Training:  50%|█████████████████████████████████████████████████████████████████▉                                                                  | 4999/10000 [1:36:43<1:35:43,  1.15s/it, loss=0.0745, lr=0.000462]
[Step 5000] Avg Loss: 0.0790
Generation: Once upon a time time
And this shall be dem'd your company's flesh,
Or I'll question you till it fall.

KING RICHARD II:
 to reverend fathers,
As 'tis back to enforce'Confess.
Training:  60%|███████████████████████████████████████████████████████████████████████████████▏                                                    | 5999/10000 [1:55:53<1:12:50,  1.09s/it, loss=0.0719, lr=0.000413]
[Step 6000] Avg Loss: 0.0610
Generation: Once upon a time
Ofiteous proper man may lived a II:
Disp thou canst notforebroke, fathers,
To make my live most bloody on hisLook.

KING RICHARD II:
We thank thee, thou
Training:  70%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                        | 6999/10000 [2:15:20<57:01,  1.14s/it, loss=0.0479, lr=0.000368]
[Step 7000] Avg Loss: 0.0490
Generation: Once upon a time,
And brave otherwise in theceless--
All Affordable and you an crown; tell me what you do,
Most bed, good fellow.

RIVERS:
My lord, in good fellow,

DUKE
Training:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                          | 7999/10000 [2:34:49<38:37,  1.16s/it, loss=0.0423, lr=0.000332]
[Step 8000] Avg Loss: 0.0435
Generation: Once upon a time would
But were so infinite.

ROMEO:
I go. Pray, ho!
What's the hour of wretched man?

FRIAR LAURENCE:
A gentlerler is Mo. constable
Training:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 8999/10000 [2:54:17<19:08,  1.15s/it, loss=0.0382, lr=0.000308]
[Step 9000] Avg Loss: 0.0389
Generation: Once upon a time
That say, which shall you milk for a civDEs,
Were musician musician musician musician, labour, Sir,
That triumph, corn corn, to have may both.

SICINIUS:
Where is this,
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 9999/10000 [3:13:53<00:01,  1.16s/it, loss=0.0302, lr=0.0003]
[Step 10000] Avg Loss: 0.0366
Generation: Once upon a time!

TRANIO:
Believe me, sir,rel.

LUCENTIO:
Sir, I have no Biondello, friends,
to il three fair and an hideous will I
oke my
Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [3:14:02<00:00,  1.16s/it, loss=0.0302, lr=0.0003]
Model saved to deepseek_final.pt

=== Generating 5 Outputs ===
Output 1:
The future of AI isailing'd:
He was smelling withBook, and Thursday Thursdayoth soul;
And till we were atheist atheist atheist atheist atheist
To the swellingistenceistenceistenceistenceve it to the people
The Ay'd after a good ears;
And
--------------------
Output 2:
Deep learning allows us to France.
What stay at theasses thatATHARINA:
No had been a keys, an enemy is not two;
And give me leave to you toARD:
Why, if you this time to let her kiss'd cannot,
--------------------
Output 3:
Once upon a time in a digital world,
To see the next night ofNoneNone upon that's
Im tempt of brother's Herschelled,
And all the he was cruel with the crown,
And in hisboards was circle
A Richmond of a tomb; Seemingemingeming
--------------------
Output 4:
The quick brown fox: thou exchange
sl hereaply inserting: Why, and late I return
Imaming my old father: tell me, that have my hand none.

FLORIZEL:
I am bound to you:
There is some
--------------------
Output 5:
Python is a programming language that is none;
For suffering I heard you shortly shortly shortly you are
A course a man my chaste you stud;
And, to grant that such a man of use!
If you may know that common Lex'd up your name;
--------------------